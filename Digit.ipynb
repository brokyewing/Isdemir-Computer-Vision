{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GMQZPEKQUnF",
        "outputId": "4eb66c52-c9c6-4fc8-a1ea-46365eb149cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.2.7-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.192-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.8.3)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
            "Collecting pi-heif<2 (from roboflow)\n",
            "  Downloading pi_heif-1.1.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting pillow-avif-plugin<2 (from roboflow)\n",
            "  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.16-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.59.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.2.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading roboflow-1.2.7-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.6/88.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics-8.3.192-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-1.1.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m115.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.16-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: pillow-avif-plugin, filetype, pi-heif, opencv-python-headless, idna, ultralytics-thop, roboflow, ultralytics\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.1.0 pillow-avif-plugin-1.5.2 roboflow-1.2.7 ultralytics-8.3.192 ultralytics-thop-2.0.16\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow numpy ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cP-DaJE5IhC",
        "outputId": "d73854a6-f2dd-4368-9899-12ea22ef7b10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in Slab-3-6 to yolov8:: 100%|██████████| 40054/40054 [00:01<00:00, 28414.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Slab-3-6 in yolov8:: 100%|██████████| 576/576 [00:00<00:00, 875.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"1CXe7ZqxLdsCrdlQeqhH\")\n",
        "project = rf.workspace(\"retina-rpndp\").project(\"slab-3-btysl\")\n",
        "version = project.version(6)\n",
        "dataset = version.download(\"yolov8\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efATUzdXO4xZ",
        "outputId": "285df9d6-917b-4d70-db94-bf1778aa236a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Yedek klasörü: /content/labels_backup\n",
            "\n",
            "=== Rapor ===\n",
            "Toplam label dosyası: 282\n",
            "Poligon içeren dosya: 0\n",
            "Toplam poligon satırı: 0\n",
            "İşlem modu: convert\n",
            "Dönüştürülen satır: 0\n",
            "Silinen/atlanan satır: 0\n"
          ]
        }
      ],
      "source": [
        "import os, glob, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# === AYARLAR ===\n",
        "# Örn: \"/content/New-Slab-Decoder-1\" gibi dataset kökü\n",
        "DATASET_ROOT = \"/content/Slab-3-6\"  # <- kendi yolun\n",
        "LABEL_FOLDERS = [\"train/labels\", \"valid/labels\", \"test/labels\"]  # hangileri varsa\n",
        "BACKUP_DIR = \"/content/labels_backup\"         # etiketleri işlem öncesi yedekle\n",
        "MODE = \"convert\"   # \"convert\" -> poligonları bbox'a çevir | \"drop\" -> poligon satırlarını tamamen sil\n",
        "\n",
        "def is_polygon_line(tokens):\n",
        "    # tokens: ['class', 'x1', 'y1', 'x2', 'y2', ...]\n",
        "    # bbox ise 5 token; polygon ise >5 (1 + 2N)\n",
        "    return len(tokens) > 5\n",
        "\n",
        "def poly_to_bbox(tokens):\n",
        "    # tokens[0] = class\n",
        "    # tokens[1:] = x1 y1 x2 y2 ... (normalize)\n",
        "    coords = list(map(float, tokens[1:]))\n",
        "    xs = coords[0::2]\n",
        "    ys = coords[1::2]\n",
        "    xmin, xmax = min(xs), max(xs)\n",
        "    ymin, ymax = min(ys), max(ys)\n",
        "    cx = (xmin + xmax) / 2.0\n",
        "    cy = (ymin + ymax) / 2.0\n",
        "    w  = (xmax - xmin)\n",
        "    h  = (ymax - ymin)\n",
        "    return [tokens[0], f\"{cx:.6f}\", f\"{cy:.6f}\", f\"{w:.6f}\", f\"{h:.6f}\"]\n",
        "\n",
        "def audit_and_fix():\n",
        "    # yedekle\n",
        "    Path(BACKUP_DIR).mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Yedek klasörü: {BACKUP_DIR}\")\n",
        "\n",
        "    total_files = 0\n",
        "    files_with_poly = 0\n",
        "    total_poly_lines = 0\n",
        "    converted_lines = 0\n",
        "    dropped_lines = 0\n",
        "\n",
        "    affected_files = []\n",
        "\n",
        "    for sub in LABEL_FOLDERS:\n",
        "        lbl_dir = Path(DATASET_ROOT) / sub\n",
        "        if not lbl_dir.exists():\n",
        "            continue\n",
        "\n",
        "        for p in lbl_dir.glob(\"*.txt\"):\n",
        "            total_files += 1\n",
        "            with open(p, \"r\", encoding=\"utf-8\") as f:\n",
        "                lines = [ln.strip() for ln in f if ln.strip()]\n",
        "\n",
        "            has_poly = False\n",
        "            new_lines = []\n",
        "            for ln in lines:\n",
        "                toks = ln.split()\n",
        "                if len(toks) < 5:\n",
        "                    # bozuk satır; atla\n",
        "                    continue\n",
        "\n",
        "                if is_polygon_line(toks):\n",
        "                    has_poly = True\n",
        "                    total_poly_lines += 1\n",
        "                    if MODE == \"convert\":\n",
        "                        # poligon -> bbox\n",
        "                        try:\n",
        "                            new_ln = \" \".join(poly_to_bbox(toks))\n",
        "                            new_lines.append(new_ln)\n",
        "                            converted_lines += 1\n",
        "                        except Exception:\n",
        "                            # dönüştürülemedi, at\n",
        "                            dropped_lines += 1\n",
        "                    elif MODE == \"drop\":\n",
        "                        # poligon satırını tamamen at\n",
        "                        dropped_lines += 1\n",
        "                    else:\n",
        "                        # bilinmeyen mod -> eskisi gibi bırak\n",
        "                        new_lines.append(ln)\n",
        "                else:\n",
        "                    # zaten bbox formatında\n",
        "                    new_lines.append(ln)\n",
        "\n",
        "            if has_poly:\n",
        "                files_with_poly += 1\n",
        "                affected_files.append(str(p))\n",
        "\n",
        "            # dosyayı yedekle ve yaz\n",
        "            if has_poly:\n",
        "                # yedek\n",
        "                dst = Path(BACKUP_DIR) / p.relative_to(DATASET_ROOT)\n",
        "                dst.parent.mkdir(parents=True, exist_ok=True)\n",
        "                shutil.copy2(p, dst)\n",
        "                # yaz\n",
        "                with open(p, \"w\", encoding=\"utf-8\") as f:\n",
        "                    f.write(\"\\n\".join(new_lines) + (\"\\n\" if new_lines else \"\"))\n",
        "\n",
        "    print(\"\\n=== Rapor ===\")\n",
        "    print(\"Toplam label dosyası:\", total_files)\n",
        "    print(\"Poligon içeren dosya:\", files_with_poly)\n",
        "    print(\"Toplam poligon satırı:\", total_poly_lines)\n",
        "    print(f\"İşlem modu: {MODE}\")\n",
        "    print(\"Dönüştürülen satır:\", converted_lines)\n",
        "    print(\"Silinen/atlanan satır:\", dropped_lines)\n",
        "\n",
        "    # Hangi dosyalar etkilendi listesi\n",
        "    if affected_files:\n",
        "        print(\"\\nPoligon içeren dosyalar (ilk 50):\")\n",
        "        for p in affected_files[:50]:\n",
        "            print(\" -\", p)\n",
        "        if len(affected_files) > 50:\n",
        "            print(f\"... ve {len(affected_files)-50} dosya daha\")\n",
        "\n",
        "# Çalıştır\n",
        "audit_and_fix()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "np4IDROl5sek",
        "outputId": "85a31f81-4b98-4247-bed0-cb0742796757"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m DATA_YAML \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/Slab-3-6/data.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# <-- kendi yolunla değiştir\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 10 sınıf (0-9) için başlangıç ağırlığı:\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myolov8s.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# digit için 'n' çok iyi hız/verim dengesi; istersen 's' de deneyebilirsin\u001b[39;00m\n\u001b[0;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m     11\u001b[0m     data\u001b[38;5;241m=\u001b[39mDATA_YAML,\n\u001b[0;32m     12\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,        \u001b[38;5;66;03m# 100 epoch\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     plots\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     25\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# ===== Doğrulama (opsiyonel) =====\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\asker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py:81\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRTDETR\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39m_get_name():  \u001b[38;5;66;03m# if RTDETR head\u001b[39;00m\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n",
            "File \u001b[1;32mc:\\Users\\asker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:151\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 151\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining\n",
            "File \u001b[1;32mc:\\Users\\asker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:295\u001b[0m, in \u001b[0;36mModel._load\u001b[1;34m(self, weights, task)\u001b[0m\n\u001b[0;32m    292\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(weights)\u001b[38;5;241m.\u001b[39mrpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtask\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
            "File \u001b[1;32mc:\\Users\\asker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1549\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[1;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[0;32m   1535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattempt_load_one_weight\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;124;03m    Load a single model weights.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1547\u001b[0m \u001b[38;5;124;03m        ckpt (dict): Model checkpoint dictionary.\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1549\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[0;32m   1550\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[0;32m   1551\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\asker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1425\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[1;34m(weight, safe_only)\u001b[0m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloads\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m attempt_download_asset\n\u001b[0;32m   1424\u001b[0m check_suffix(file\u001b[38;5;241m=\u001b[39mweight, suffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1425\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_download_asset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# search online if missing locally\u001b[39;00m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m temporary_modules(\n\u001b[0;32m   1428\u001b[0m         modules\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   1429\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multralytics.yolo.utils\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multralytics.utils\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1437\u001b[0m         },\n\u001b[0;32m   1438\u001b[0m     ):\n",
            "File \u001b[1;32mc:\\Users\\asker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\downloads.py:472\u001b[0m, in \u001b[0;36mattempt_download_asset\u001b[1;34m(file, repo, release, **kwargs)\u001b[0m\n\u001b[0;32m    469\u001b[0m         safe_download(url\u001b[38;5;241m=\u001b[39murl, file\u001b[38;5;241m=\u001b[39mfile, min_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e5\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m repo \u001b[38;5;241m==\u001b[39m GITHUB_ASSETS_REPO \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m GITHUB_ASSETS_NAMES:\n\u001b[1;32m--> 472\u001b[0m     \u001b[43msafe_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdownload_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrelease\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_bytes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    475\u001b[0m     tag, assets \u001b[38;5;241m=\u001b[39m get_github_assets(repo, release)\n",
            "File \u001b[1;32mc:\\Users\\asker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\downloads.py:348\u001b[0m, in \u001b[0;36msafe_download\u001b[1;34m(url, file, dir, unzip, delete, curl, retry, min_bytes, exist_ok, progress)\u001b[0m\n\u001b[0;32m    346\u001b[0m     expected_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Can't get size with curl\u001b[39;00m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# urllib download\u001b[39;00m\n\u001b[1;32m--> 348\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m    349\u001b[0m         expected_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(response\u001b[38;5;241m.\u001b[39mgetheader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Length\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m    350\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m TQDM(\n\u001b[0;32m    351\u001b[0m             total\u001b[38;5;241m=\u001b[39mexpected_size,\n\u001b[0;32m    352\u001b[0m             desc\u001b[38;5;241m=\u001b[39mdesc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    356\u001b[0m             unit_divisor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,\n\u001b[0;32m    357\u001b[0m         ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n",
            "File \u001b[1;32mc:\\Users\\asker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:215\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\asker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:515\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    512\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    514\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 515\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    518\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\asker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:532\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    531\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 532\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m    533\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[1;32mc:\\Users\\asker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:492\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    491\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 492\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    494\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[1;32mc:\\Users\\asker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:1392\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1393\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\asker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:1344\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1343\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1344\u001b[0m         \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1345\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m   1347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n",
            "File \u001b[1;32mc:\\Users\\asker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1338\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, url, body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m{}, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   1336\u001b[0m             encode_chunked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1338\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\asker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1384\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(body, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1381\u001b[0m     \u001b[38;5;66;03m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[0;32m   1382\u001b[0m     \u001b[38;5;66;03m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[0;32m   1383\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1384\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\asker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1333\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1333\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\asker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1093\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1091\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer)\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1093\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1096\u001b[0m \n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1099\u001b[0m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\asker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m-> 1037\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1038\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1039\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
            "File \u001b[1;32mc:\\Users\\asker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1479\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1477\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m-> 1479\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1480\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\asker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:455\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    450\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    451\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    452\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\asker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1041\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m   1039\u001b[0m                 \u001b[38;5;66;03m# non-blocking\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1041\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1043\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\asker\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1319\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m block:\n\u001b[0;32m   1318\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1319\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "# ===== Eğitim =====\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Roboflow'dan YOLOv8 formatında indirdiğin digit dataset'inin data.yaml yolu\n",
        "DATA_YAML = \"/content/Slab-3-6/data.yaml\"  # <-- kendi yolunla değiştir\n",
        "\n",
        "# 10 sınıf (0-9) için başlangıç ağırlığı:\n",
        "model = YOLO(\"yolov8s.pt\")  # digit için 'n' çok iyi hız/verim dengesi; istersen 's' de deneyebilirsin\n",
        "\n",
        "model.train(\n",
        "    data=DATA_YAML,\n",
        "    epochs=200,        # 100 epoch\n",
        "    imgsz=2048,         # digit crop'ları için uygun (160/192 de denenebilir)\n",
        "    batch=-1,          # otomatik batch size\n",
        "    device=0,          # GPU\n",
        "    patience=20,       # erken durdurma: 20 epoch iyileşme yoksa dur\n",
        "    cos_lr=True,       # cosine LR schedule\n",
        "    optimizer=\"AdamW\",   # alternatif: \"AdamW\"\n",
        "    amp=True,          # mixed precision\n",
        "    workers=8,         # dataloader worker sayısı (VRAM/CPU'ya göre 4-8)\n",
        "    seed=42,\n",
        "    save_period=10,    # her 10 epokta bir ağırlık kaydet (opsiyonel)\n",
        "    plots=True\n",
        ")\n",
        "\n",
        "# ===== Doğrulama (opsiyonel) =====\n",
        "best = YOLO(\"runs/detect/train/weights/best.pt\")\n",
        "best.val(data=DATA_YAML, imgsz=128, device=0)\n",
        "\n",
        "# ===== Örnek tahmin (opsiyonel) =====\n",
        "best.predict(source=\"/content/Slab-3-6/valid/images\", conf=0.75, imgsz=128, save=True, device=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgqwoMU43XPu",
        "outputId": "edd86a26-9869-42ce-e5b7-1ad2c878d4bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 11/11 [00:00<00:00, 13.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== GENEL ÖZET =====\n",
            "Görüntü sayısı     : 11\n",
            "Toplam TP / FP / FN: 1107 / 17 / 10\n",
            "Precision          : 0.9849\n",
            "Recall             : 0.9910\n",
            "F1                 : 0.9880\n",
            "\n",
            "===== SINIF BAZLI =====\n",
            "[0] TP:228 FP:9 FN:0  P:0.962 R:1.000 F1:0.981\n",
            "[1] TP:191 FP:2 FN:2  P:0.990 R:0.990 F1:0.990\n",
            "[2] TP:245 FP:1 FN:1  P:0.996 R:0.996 F1:0.996\n",
            "[3] TP:141 FP:0 FN:0  P:1.000 R:1.000 F1:1.000\n",
            "[4] TP:85 FP:1 FN:0  P:0.988 R:1.000 F1:0.994\n",
            "[5] TP:87 FP:0 FN:2  P:1.000 R:0.978 F1:0.989\n",
            "[6] TP:39 FP:0 FN:3  P:1.000 R:0.929 F1:0.963\n",
            "[7] TP:35 FP:0 FN:0  P:1.000 R:1.000 F1:1.000\n",
            "[8] TP:30 FP:2 FN:0  P:0.937 R:1.000 F1:0.968\n",
            "[9] TP:26 FP:2 FN:2  P:0.929 R:0.929 F1:0.929\n",
            "\n",
            "Per-image istatistik CSV: /content/eval_out/per_image_stats.csv\n",
            "En zor 11 görsel 'hard_cases/' klasörüne kopyalanıyor...\n",
            "\n",
            "Bitti. Çıktılar:\n",
            "- Görsel değerlendirmeler: /content/eval_out/viz\n",
            "- Zor vakalar:            /content/eval_out/hard_cases\n",
            "- Confusion matrix (csv): /content/eval_out/confusion_matrix_tp_only.csv\n",
            "- Per-image istatistik:   /content/eval_out/per_image_stats.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ===================== YOLOv8 DEĞERLENDİRME: FP/FN ANALİZİ =====================\n",
        "# Gereksinimler: pip install ultralytics opencv-python tqdm\n",
        "# (Colab'da bir kez çalıştır: !pip -q install ultralytics opencv-python tqdm)\n",
        "\n",
        "import os, glob, math, shutil, csv\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -------------------- KULLANICI AYARLARI (DÜZENLE) --------------------\n",
        "WEIGHTS   = \"/content/runs/detect/train/weights/best.pt\"   # YOLOv8 ağırlığın\n",
        "IMG_DIR   = \"/content/Slab-3-6/test/images\"          # test görüntüleri\n",
        "LBL_DIR   = \"/content/Slab-3-6/test/labels\"          # YOLO label txt'leri\n",
        "OUT_DIR   = Path(\"/content/eval_out\")    # çıktı klasörü\n",
        "CLASS_NAMES = [str(i) for i in range(10)]                    # sınıf adları (0-9)\n",
        "IMG_EXTS = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\",\".tif\",\".tiff\",\".JPG\",\".JPEG\",\".PNG\")\n",
        "CONF_THRESH = 0.25   # model çıktı eşiği\n",
        "IOU_THRESH  = 0.50   # eşleştirme IoU eşiği\n",
        "SAVE_TOP_HARDEST = 40  # en zor vakalardan kaç tanesini \"hard_cases\" klasörüne alalım\n",
        "\n",
        "# -------------------- MODELİ YÜKLE --------------------\n",
        "from ultralytics import YOLO\n",
        "model = YOLO(WEIGHTS)\n",
        "\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "(OUT_DIR / \"viz\").mkdir(exist_ok=True)\n",
        "(OUT_DIR / \"hard_cases\").mkdir(exist_ok=True)\n",
        "\n",
        "# -------------------- YARDIMCI FONKSİYONLAR --------------------\n",
        "def yolo_to_xyxy(box, W, H):\n",
        "    # YOLO: cx, cy, w, h (normalize) -> xyxy (piksel)\n",
        "    cx, cy, w, h = box\n",
        "    cx, cy, w, h = cx*W, cy*H, w*W, h*H\n",
        "    x1 = max(0, cx - w/2); y1 = max(0, cy - h/2)\n",
        "    x2 = min(W-1, cx + w/2); y2 = min(H-1, cy + h/2)\n",
        "    return [x1, y1, x2, y2]\n",
        "\n",
        "def read_labels_txt(txt_path, W, H):\n",
        "    \"\"\" YOLO txt -> list of dict: {'cls':int, 'xyxy':[x1,y1,x2,y2]} \"\"\"\n",
        "    out = []\n",
        "    if not os.path.exists(txt_path):\n",
        "        return out\n",
        "    with open(txt_path, \"r\") as f:\n",
        "        for ln in f:\n",
        "            parts = ln.strip().split()\n",
        "            if len(parts) < 5:\n",
        "                continue\n",
        "            cls = int(float(parts[0]))\n",
        "            cx, cy, w, h = map(float, parts[1:5])\n",
        "            xyxy = yolo_to_xyxy([cx,cy,w,h], W, H)\n",
        "            out.append({\"cls\": cls, \"xyxy\": xyxy})\n",
        "    return out\n",
        "\n",
        "def iou_xyxy(a, b):\n",
        "    ax1, ay1, ax2, ay2 = a\n",
        "    bx1, by1, bx2, by2 = b\n",
        "    inter_x1, inter_y1 = max(ax1,bx1), max(ay1,by1)\n",
        "    inter_x2, inter_y2 = min(ax2,bx2), min(ay2,by2)\n",
        "    iw, ih = max(0, inter_x2 - inter_x1), max(0, inter_y2 - inter_y1)\n",
        "    inter = iw * ih\n",
        "    a_area = max(0, (ax2-ax1)) * max(0, (ay2-ay1))\n",
        "    b_area = max(0, (bx2-bx1)) * max(0, (by2-by1))\n",
        "    union = a_area + b_area - inter + 1e-9\n",
        "    return inter / union\n",
        "\n",
        "def match_by_iou(preds, gts, iou_thr):\n",
        "    \"\"\"\n",
        "    Sınıf eşleşmeli greedy eşleştirme.\n",
        "    preds/gts: list of dict {'cls':int,'xyxy':[..], 'conf':float (preds için olabilir)}\n",
        "    Dönüş: lists of indices: matched_pairs [(pi, gi)], unmatched_pred_indices, unmatched_gt_indices\n",
        "    \"\"\"\n",
        "    if not preds and not gts:\n",
        "        return [], [], []\n",
        "    used_g = set()\n",
        "    pairs = []\n",
        "\n",
        "    # Her sınıf için ayrı ayrı eşleştir (daha doğru)\n",
        "    classes = sorted(set([p['cls'] for p in preds] + [g['cls'] for g in gts]))\n",
        "    for c in classes:\n",
        "        p_idx = [i for i,p in enumerate(preds) if p['cls']==c]\n",
        "        g_idx = [j for j,g in enumerate(gts)   if g['cls']==c]\n",
        "        # IoU matrisini kur\n",
        "        iou_mat = []\n",
        "        for i in p_idx:\n",
        "            row = []\n",
        "            for j in g_idx:\n",
        "                row.append(iou_xyxy(preds[i]['xyxy'], gts[j]['xyxy']))\n",
        "            iou_mat.append(row)\n",
        "\n",
        "        # Greedy: en yüksek IoU'lardan aşağı sırala\n",
        "        cand = []\n",
        "        for ii, i in enumerate(p_idx):\n",
        "            for jj, j in enumerate(g_idx):\n",
        "                cand.append((iou_mat[ii][jj], i, j))\n",
        "        cand.sort(reverse=True, key=lambda x: x[0])\n",
        "\n",
        "        used_p_local = set()\n",
        "        used_g_local = set()\n",
        "        for iou, pi, gj in cand:\n",
        "            if iou < iou_thr:\n",
        "                break\n",
        "            if (pi not in used_p_local) and (gj not in used_g_local):\n",
        "                pairs.append((pi, gj))\n",
        "                used_p_local.add(pi)\n",
        "                used_g_local.add(gj)\n",
        "\n",
        "    matched_p = set([p for p,_ in pairs])\n",
        "    matched_g = set([g for _,g in pairs])\n",
        "    up = [i for i in range(len(preds)) if i not in matched_p]\n",
        "    ug = [j for j in range(len(gts))   if j not in matched_g]\n",
        "    return pairs, up, ug\n",
        "\n",
        "def draw_boxes(img, gts, preds, pairs, up, ug, save_path):\n",
        "    \"\"\"\n",
        "    Renk kodu:\n",
        "      - GT kutuları: Yeşil (FN olan GT'ler sarı kalın)\n",
        "      - Eşleşmiş TP (pred): Mavi\n",
        "      - Eşleşemeyen FP (pred): Kırmızı\n",
        "    Etiket: sınıf adı + skor (varsa)\n",
        "    \"\"\"\n",
        "    H, W = img.shape[:2]\n",
        "    img_vis = img.copy()\n",
        "\n",
        "    # Önce tüm GT'leri yeşil çiz\n",
        "    for i, g in enumerate(gts):\n",
        "        x1,y1,x2,y2 = map(int, g[\"xyxy\"])\n",
        "        cv2.rectangle(img_vis, (x1,y1), (x2,y2), (0,255,0), 2) # GT yeşil\n",
        "        label = f\"GT:{CLASS_NAMES[g['cls']] if g['cls'] < len(CLASS_NAMES) else g['cls']}\"\n",
        "        cv2.putText(img_vis, label, (x1, max(15,y1-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,200,0), 2)\n",
        "\n",
        "    # FN (eşleşemeyen GT): sarı kalın kontur\n",
        "    for gi in ug:\n",
        "        x1,y1,x2,y2 = map(int, gts[gi][\"xyxy\"])\n",
        "        cv2.rectangle(img_vis, (x1,y1), (x2,y2), (0,255,255), 3)\n",
        "        cv2.putText(img_vis, \"FN\", (x1, min(H-5,y2+15)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)\n",
        "\n",
        "    # TP: eşleşmiş pred'ler mavi\n",
        "    for pi, gi in pairs:\n",
        "        pr = preds[pi]\n",
        "        x1,y1,x2,y2 = map(int, pr[\"xyxy\"])\n",
        "        cv2.rectangle(img_vis, (x1,y1), (x2,y2), (255,0,0), 2)\n",
        "        sc = pr.get(\"conf\", None)\n",
        "        label = f\"TP:{CLASS_NAMES[pr['cls']] if pr['cls'] < len(CLASS_NAMES) else pr['cls']}\"\n",
        "        if sc is not None: label += f\" {sc:.2f}\"\n",
        "        cv2.putText(img_vis, label, (x1, max(15,y1-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,0,0), 2)\n",
        "\n",
        "    # FP: kırmızı\n",
        "    for pi in up:\n",
        "        pr = preds[pi]\n",
        "        x1,y1,x2,y2 = map(int, pr[\"xyxy\"])\n",
        "        cv2.rectangle(img_vis, (x1,y1), (x2,y2), (0,0,255), 2)\n",
        "        sc = pr.get(\"conf\", None)\n",
        "        label = f\"FP:{CLASS_NAMES[pr['cls']] if pr['cls'] < len(CLASS_NAMES) else pr['cls']}\"\n",
        "        if sc is not None: label += f\" {sc:.2f}\"\n",
        "        cv2.putText(img_vis, label, (x1, max(15,y1-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,200), 2)\n",
        "\n",
        "    cv2.imwrite(str(save_path), img_vis)\n",
        "\n",
        "def confusion_matrix_update(cm, pairs, preds, gts, up, ug, num_classes):\n",
        "    # TP'ler: doğru sınıfa +1\n",
        "    for pi, gi in pairs:\n",
        "        c = preds[pi]['cls']\n",
        "        cm[c, c] += 1\n",
        "    # FP: tahmin edilen sınıfta \"pred col\", \"GT yok\" gibi saymak yerine standart CM için\n",
        "    # her FP'yi \"pred sınıfı, GT sınıfı = None\" diye koyamayız. CM sınıflar arası dağılım için\n",
        "    # basitçe FP sayısını ayrı tutacağız. (Aşağıda FP_total/FN_total ayrı tutuluyor.)\n",
        "    # Eğer GT'yi yanlış sınıfa eşleşmiş gibi saymak istersek gelişmiş bir dağıtım gerekir.\n",
        "    return cm\n",
        "\n",
        "# -------------------- DEĞERLENDİRME --------------------\n",
        "image_paths = []\n",
        "for ext in IMG_EXTS:\n",
        "    image_paths += glob.glob(os.path.join(IMG_DIR, f\"*{ext}\"))\n",
        "image_paths = sorted(image_paths)\n",
        "\n",
        "assert len(image_paths) > 0, f\"Test klasöründe görsel bulunamadı: {IMG_DIR}\"\n",
        "\n",
        "# Sayaçlar\n",
        "num_classes = max(len(CLASS_NAMES), 1)\n",
        "CM = np.zeros((num_classes, num_classes), dtype=np.int64)  # yalnızca TP'ler diyagonal büyür\n",
        "TP_total = 0\n",
        "FP_total = 0\n",
        "FN_total = 0\n",
        "per_class = {i: {\"TP\":0,\"FP\":0,\"FN\":0} for i in range(num_classes)}\n",
        "\n",
        "rows_csv = []\n",
        "hardness_scores = []  # (score, img_path) score = FN*2 + FP (örnek)\n",
        "\n",
        "for img_path in tqdm(image_paths, desc=\"Evaluating\"):\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        continue\n",
        "    H, W = img.shape[:2]\n",
        "\n",
        "    # GT oku\n",
        "    base = os.path.splitext(os.path.basename(img_path))[0]\n",
        "    lbl_path = os.path.join(LBL_DIR, base + \".txt\")\n",
        "    gts = read_labels_txt(lbl_path, W, H)\n",
        "\n",
        "    # Tahmin\n",
        "    res = model.predict(img, conf=CONF_THRESH, verbose=False)[0]\n",
        "    preds = []\n",
        "    if res.boxes is not None and len(res.boxes) > 0:\n",
        "        xyxy = res.boxes.xyxy.cpu().numpy()\n",
        "        cls   = res.boxes.cls.cpu().numpy().astype(int)\n",
        "        conf  = res.boxes.conf.cpu().numpy()\n",
        "        for k in range(len(cls)):\n",
        "            preds.append({\"cls\": int(cls[k]), \"xyxy\": xyxy[k].tolist(), \"conf\": float(conf[k])})\n",
        "\n",
        "    # Eşleştirme\n",
        "    pairs, up, ug = match_by_iou(preds, gts, IOU_THRESH)\n",
        "\n",
        "    # Sayaçlar\n",
        "    TP = len(pairs)\n",
        "    FP = len(up)\n",
        "    FN = len(ug)\n",
        "\n",
        "    TP_total += TP; FP_total += FP; FN_total += FN\n",
        "    for pi, gi in pairs:\n",
        "        c = preds[pi]['cls']\n",
        "        per_class.setdefault(c, {\"TP\":0,\"FP\":0,\"FN\":0})\n",
        "        per_class[c][\"TP\"] += 1\n",
        "    for pi in up:\n",
        "        c = preds[pi]['cls']\n",
        "        per_class.setdefault(c, {\"TP\":0,\"FP\":0,\"FN\":0})\n",
        "        per_class[c][\"FP\"] += 1\n",
        "    for gi in ug:\n",
        "        c = gts[gi]['cls'] if gts else 0\n",
        "        per_class.setdefault(c, {\"TP\":0,\"FP\":0,\"FN\":0})\n",
        "        per_class[c][\"FN\"] += 1\n",
        "\n",
        "    # CM güncelle (sadece TP'leri diyagonale ekliyoruz)\n",
        "    CM = confusion_matrix_update(CM, pairs, preds, gts, up, ug, num_classes)\n",
        "\n",
        "    # Görselleştir & kaydet\n",
        "    save_path = OUT_DIR / \"viz\" / f\"{base}.jpg\"\n",
        "    draw_boxes(img, gts, preds, pairs, up, ug, save_path)\n",
        "\n",
        "    # CSV satırı\n",
        "    rows_csv.append({\n",
        "        \"image\": img_path,\n",
        "        \"gt_count\": len(gts),\n",
        "        \"pred_count\": len(preds),\n",
        "        \"TP\": TP, \"FP\": FP, \"FN\": FN,\n",
        "        \"label_file_exists\": os.path.exists(lbl_path)\n",
        "    })\n",
        "\n",
        "    hardness_scores.append((FN*2 + FP, img_path))  # FN'lere iki kat ağırlık ver\n",
        "\n",
        "# -------------------- ÖZET METRİKLER --------------------\n",
        "prec = TP_total / (TP_total + FP_total + 1e-9)\n",
        "rec  = TP_total / (TP_total + FN_total + 1e-9)\n",
        "f1   = 2*prec*rec / (prec + rec + 1e-9)\n",
        "\n",
        "print(\"\\n===== GENEL ÖZET =====\")\n",
        "print(f\"Görüntü sayısı     : {len(image_paths)}\")\n",
        "print(f\"Toplam TP / FP / FN: {TP_total} / {FP_total} / {FN_total}\")\n",
        "print(f\"Precision          : {prec:.4f}\")\n",
        "print(f\"Recall             : {rec:.4f}\")\n",
        "print(f\"F1                 : {f1:.4f}\")\n",
        "\n",
        "print(\"\\n===== SINIF BAZLI =====\")\n",
        "for c in range(num_classes):\n",
        "    TPc = per_class[c][\"TP\"]\n",
        "    FPc = per_class[c][\"FP\"]\n",
        "    FNc = per_class[c][\"FN\"]\n",
        "    Pc = TPc / (TPc + FPc + 1e-9)\n",
        "    Rc = TPc / (TPc + FNc + 1e-9)\n",
        "    F1c = 2*Pc*Rc / (Pc + Rc + 1e-9)\n",
        "    name = CLASS_NAMES[c] if c < len(CLASS_NAMES) else str(c)\n",
        "    print(f\"[{name}] TP:{TPc} FP:{FPc} FN:{FNc}  P:{Pc:.3f} R:{Rc:.3f} F1:{F1c:.3f}\")\n",
        "\n",
        "# Karışıklık matrisi (yalnızca TP diyagonal). İstersen kaydet:\n",
        "np.savetxt(OUT_DIR / \"confusion_matrix_tp_only.csv\", CM, fmt=\"%d\", delimiter=\",\")\n",
        "\n",
        "# Per-image CSV\n",
        "csv_path = OUT_DIR / \"per_image_stats.csv\"\n",
        "with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    w = csv.DictWriter(f, fieldnames=list(rows_csv[0].keys()))\n",
        "    w.writeheader()\n",
        "    w.writerows(rows_csv)\n",
        "print(f\"\\nPer-image istatistik CSV: {csv_path}\")\n",
        "\n",
        "# -------------------- ZOR VAKALARIN AYIKLANMASI --------------------\n",
        "hardness_scores.sort(reverse=True, key=lambda x: x[0])\n",
        "top_hard = hardness_scores[:SAVE_TOP_HARDEST]\n",
        "print(f\"En zor {len(top_hard)} görsel 'hard_cases/' klasörüne kopyalanıyor...\")\n",
        "for score, p in top_hard:\n",
        "    base = os.path.basename(p)\n",
        "    vis = OUT_DIR / \"viz\" / (os.path.splitext(base)[0] + \".jpg\")\n",
        "    src = vis if vis.exists() else p\n",
        "    dst = OUT_DIR / \"hard_cases\" / os.path.basename(src)\n",
        "    if src.exists():\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "print(\"\\nBitti. Çıktılar:\")\n",
        "print(f\"- Görsel değerlendirmeler: {OUT_DIR / 'viz'}\")\n",
        "print(f\"- Zor vakalar:            {OUT_DIR / 'hard_cases'}\")\n",
        "print(f\"- Confusion matrix (csv): {OUT_DIR / 'confusion_matrix_tp_only.csv'}\")\n",
        "print(f\"- Per-image istatistik:   {csv_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
